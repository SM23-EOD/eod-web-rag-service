# ADR-0003: Protocolo MCP para Integraci√≥n RAG

**Estado:** Aceptado ‚úì

**Fecha:** 2026-02-09

**Tipo:** Arqueolog√≠a (Decisi√≥n Retroactiva)

## Contexto

El proyecto necesitaba comunicarse con un backend que provee capacidades de Retrieval-Augmented Generation (RAG). Los requisitos eran:

- Protocolo estandarizado para llamadas de herramientas (tool calling)
- Capacidad de pasar queries y recibir respuestas con fuentes
- Soporte para streaming opcional
- Feedback loop (thumbs up/down en respuestas)
- Identificaci√≥n de sesiones para contexto conversacional

## Decisi√≥n

Adoptar el **protocolo MCP (Model Context Protocol)** como interfaz est√°ndar para comunicaci√≥n con el backend RAG.

**Endpoint principal:**
- `POST /api/v1/mcp/tools/call` - Ejecuta herramientas MCP

**Endpoint de feedback:**
- `POST /api/v1/feedback` - Env√≠a feedback sobre respuestas

**Estructura de request:**
```json
{
  "tool_name": "generate_rag_answer",
  "arguments": {
    "query": "user question here",
    "session_id": "web",
    "include_sources": true
  }
}
```

**Estructura de response:**
```json
{
  "content": [
    {
      "type": "text",
      "text": "Respuesta del asistente..."
    }
  ],
  "sources": [
    {
      "title": "Document title",
      "url": "https://...",
      "relevance": 0.95
    }
  ]
}
```

## Consecuencias

### Positivas

‚úÖ **Protocolo estandarizado**: MCP es un est√°ndar emergente de Anthropic para tool calling, lo que facilita integraci√≥n con otros sistemas compatibles.

‚úÖ **Extensibilidad**: F√°cil agregar nuevas herramientas sin cambiar la interfaz del widget (solo cambiar el `tool-name`).

‚úÖ **Separaci√≥n de responsabilidades**: El widget solo hace HTTP calls, el backend maneja toda la l√≥gica RAG.

‚úÖ **Soporte multi-sesi√≥n**: El `session_id` permite mantener contexto conversacional en el backend.

‚úÖ **Metadata rica**: Las respuestas incluyen fuentes con relevancia, permitiendo transparencia en la generaci√≥n.

### Negativas

‚ö†Ô∏è **Acoplamiento a backend espec√≠fico**: El widget asume que existe un backend compatible con MCP en el endpoint configurado.

‚ö†Ô∏è **Sin versionado de API**: No hay versionado expl√≠cito en el protocolo, cambios breaking podr√≠an romper compatibilidad.

‚ö†Ô∏è **Error handling gen√©rico**: Los errores del backend se manejan de forma b√°sica sin c√≥digos espec√≠ficos.

‚ö†Ô∏è **Sin retry logic**: No hay reintentos autom√°ticos en caso de fallo de red.

### Deuda T√©cnica Identificada

üî¥ **Falta validaci√≥n de respuesta**: No se valida el schema de la respuesta MCP, errores malformados causan crashes.

üî¥ **Sin timeout configurado**: Las requests pueden colgarse indefinidamente si el backend no responde.

üü° **Feedback hardcoded**: La URL de feedback se deriva del endpoint MCP (`endpoint.replace(/\/mcp\/tools\/call$/, '/feedback')`), lo cual es fr√°gil.

üü° **Sin cach√©**: Queries repetidas hacen llamadas id√©nticas al backend sin cach√© local.

üü° **Sin soporte para streaming**: MCP soporta streaming de respuestas pero el widget no lo implementa, causando latencia percibida alta en respuestas largas.

## Alternativas Consideradas

### 1. REST API Personalizada
- **Pros**: Control total del contrato, optimizable para este caso de uso
- **Contras**: No est√°ndar, requiere documentaci√≥n custom, menos extensible
- **Raz√≥n de rechazo**: Preferimos est√°ndar emergente sobre API propietaria

### 2. GraphQL
- **Pros**: Query exacto de datos necesarios, typed schema
- **Contras**: Overhead de cliente GraphQL, complejidad para caso de uso simple
- **Raz√≥n de rechazo**: Over-engineering para llamadas de herramientas simples

### 3. OpenAI Chat Completions API
- **Pros**: Est√°ndar de facto en la industria, ampliamente conocido
- **Contras**: Dise√±ado para chat, no para tool calling con RAG sources
- **Raz√≥n de rechazo**: MCP es m√°s apropiado para tool calling

### 4. gRPC
- **Pros**: Altamente eficiente, typed contracts con Protocol Buffers
- **Contras**: Requiere compilaci√≥n de protobuf, no soportado nativamente en browsers
- **Raz√≥n de rechazo**: Complejidad excesiva, problemas de compatibilidad web

## Notas de Implementaci√≥n

### C√≥digo de Llamada MCP

```javascript
async sendMessage(message) {
  const payload = {
    tool_name: this.toolName,
    arguments: {
      query: message,
      session_id: this.sessionId,
      include_sources: this.includeSources,
    },
  };

  const response = await fetch(this.endpoint, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify(payload),
  });

  const data = await response.json();
  return this.parseResponse(data);
}
```

### Mejoras Futuras Sugeridas

1. **Validaci√≥n de schema con Zod/TypeBox**
2. **Retry con exponential backoff**
3. **Timeout configurable** (default 30s)
4. **Streaming con Server-Sent Events**
5. **Versionado de API** (`/api/v2/mcp/tools/call`)
6. **Cache con LRU** para queries recientes

## Referencias

- [Model Context Protocol (MCP) - Anthropic](https://www.anthropic.com/news/model-context-protocol)
- Backend requerido: [eod-api-rag-service](https://github.com/envios23/eod-api-rag-service)
- C√≥digo fuente: `src/assistant-widget.js` (m√©todo `sendMessage`)
