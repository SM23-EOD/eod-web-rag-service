# [BACKEND] ‚ö†Ô∏è 7 Endpoints Rotos ‚Äî Metrics, Feedback, Retrieval, Reset

**Prioridad**: üî¥ ALTA  
**Reportado**: 2026-02-15  
**√öltima revisi√≥n**: 2026-02-16 (auditor√≠a completa)  
**Contexto**: Tras la correcci√≥n de tenant isolation y migraci√≥n de datos, varios subsistemas tienen bugs persistentes. El frontend est√° adaptado con `retries: 0` y degradaci√≥n elegante.

---

## üìã Resumen

**29 endpoints testeados** ‚Äî 22 funcionan, 7 fallan.

**‚úÖ FUNCIONAN (22 endpoints)**:
- `/health`, `/tenants`, `/tenants/{id}`, `/stats`, `/models` ‚Üí 200
- `/agents`, `/api-keys`, `/conversations`, `/tasks` ‚Üí 200
- `/documents`, `/documents/{id}`, `/documents/stats/summary`, `/documents/upload`, `/documents/process-pending` ‚Üí 200
- `/chat/completions`, `/query` (200 pero sin retrieval ‚Äî ver Bug 4)
- `DELETE /cache` ‚Üí 200
- `/mcp/health`, `/mcp/tools`, `/mcp/prompts`, `/mcp/resources` ‚Üí 200

**‚ùå ROTOS (7 endpoints)**:
- `POST/GET /feedback`, `/feedback/stats` ‚Üí 500 (intermitente, asyncpg bug)
- `GET /metrics/dashboard|coverage|gaps|grounding` ‚Üí 500
- `POST /documents/reset-reindex` ‚Üí 500
- `POST /documents/sync/directory` ‚Üí 500
- `POST /query` ‚Üí 200 pero 0 chunks retrieved de 26 disponibles

**‚úÖ RESUELTOS desde √∫ltimo reporte**:
- `/api-keys`, `/conversations`, `/tasks` ‚Üí Antes 502, ahora 200
- `/documents` ‚Üí 7 documentos con metadata correcta

---

## üêõ Bug 1: Feedback ‚Äî Intermitente 200/500 (asyncpg event loop)

### Estado: ‚ö†Ô∏è INTERMITENTE ‚Äî funciona a veces, falla otras

### Endpoints afectados
| M√©todo | Endpoint | HTTP | Error |
|--------|----------|------|-------|
| `POST` | `/api/v2/feedback` | 200/500 | `Error interno al guardar feedback.` |
| `GET` | `/api/v2/feedback?limit=5` | 200/500 | `Error interno al obtener feedback.` |
| `GET` | `/api/v2/feedback/stats` | 200/500 | `Error interno al obtener estad√≠sticas.` |

### Reproducci√≥n
```bash
# A veces retorna 200, a veces 500 (race condition)
curl -sS -w "\nHTTP: %{http_code}" -X POST "http://167.172.225.44/api/v2/feedback" \
  -H "Content-Type: application/json" \
  -d '{"tenant_id":"envios23","query":"test","response":"test","rating":"positive"}'

curl -sS -w "\nHTTP: %{http_code}" "http://167.172.225.44/api/v2/feedback/stats"
```

### Causa ra√≠z (identificada en docker logs)
```
RuntimeError: Task <...> got Future <Future pending> attached to a different loop
```
Archivos afectados en el backend:
- `pg_feedback_repository.py` ‚Äî pool de conexiones asyncpg con event loop corrupto
- `pg_feedback_insights.py` ‚Äî mismo problema
- `pg_gap_log.py` ‚Äî mismo problema
- `pg_cost_tracker.py` ‚Äî mismo problema

### Fix requerido
Inicializar el pool de conexiones asyncpg en el event loop correcto. Cambiar la creaci√≥n del pool para usar `asyncpg.create_pool()` dentro del handler de startup de FastAPI, no en tiempo de importaci√≥n del m√≥dulo.

### Impacto Frontend
- Chat: feedback a veces se guarda, a veces muestra error
- Quality: feedback list vac√≠a o con error intermitente
- Admin Analytics: panel de feedback intermitente

---

## üêõ Bug 2: Metrics ‚Äî Todos los Endpoints 500

### Endpoints afectados
| M√©todo | Endpoint | HTTP | Error |
|--------|----------|------|-------|
| `GET` | `/api/v2/metrics/dashboard?tenant_id=envios23` | 500 | `Error al obtener m√©tricas del dashboard.` |
| `GET` | `/api/v2/metrics/coverage?tenant_id=envios23` | 500 | `internal_error` |
| `GET` | `/api/v2/metrics/gaps?tenant_id=envios23` | 500 | `internal_error` |
| `GET` | `/api/v2/metrics/grounding?tenant_id=envios23` | 500 | `internal_error` |

### Reproducci√≥n
```bash
curl -sS "http://167.172.225.44/api/v2/metrics/dashboard?tenant_id=envios23"
# ‚Üí 500: {"detail":{"error":"internal_error","message":"Error al obtener m√©tricas del dashboard."}}

curl -sS "http://167.172.225.44/api/v2/metrics/coverage?tenant_id=envios23"
# ‚Üí 500 (mismo patr√≥n)

curl -sS "http://167.172.225.44/api/v2/metrics/gaps?tenant_id=envios23"
# ‚Üí 500

curl -sS "http://167.172.225.44/api/v2/metrics/grounding?tenant_id=envios23"
# ‚Üí 500
```

### Causa ra√≠z (identificada en docker logs)
```
AttributeError: 'Column' object has no attribute 'isnull'
```
SQLAlchemy no tiene `.isnull()` ‚Äî deber√≠a ser `.is_(None)`.

### Fix requerido
Buscar todas las ocurrencias de `.isnull()` en el c√≥digo de metrics y reemplazar por `.is_(None)`.

### Impacto Frontend
- Quality Dashboard: todas las m√©tricas muestran "‚Äî"
- Admin Analytics: sin datos de cobertura ni grounding
- Frontend adaptado con `retries: 0` ‚Äî no reintenta, degrada elegante

---

## üêõ Bug 3: Reset-Reindex + Sync Directory ‚Äî 500

### Endpoints afectados
| M√©todo | Endpoint | HTTP | Error |
|--------|----------|------|-------|
| `POST` | `/api/v2/documents/reset-reindex?tenant_id=envios23` | 500 | `An internal error occurred during reset and reindex.` |
| `POST` | `/api/v2/documents/sync/directory?directory=/app/storage` | 500 | `An internal error occurred while syncing the directory.` |

### Reproducci√≥n
```bash
curl -sS -X POST "http://167.172.225.44/api/v2/documents/reset-reindex?tenant_id=envios23"
# ‚Üí 500: {"detail":"An internal error occurred during reset and reindex."}

curl -sS -X POST "http://167.172.225.44/api/v2/documents/sync/directory?directory=/app/storage&tenant_id=envios23"
# ‚Üí 500: {"detail":"An internal error occurred while syncing the directory."}
```

### Causa ra√≠z (identificada en docker logs)
```
AttributeError: 'DocumentManagementService' object has no attribute 'full_reset_and_reindex'
```
El m√©todo `full_reset_and_reindex` no existe en `DocumentManagementService`. Falta implementar o renombrar.

### Fix requerido
Implementar `full_reset_and_reindex()` en `DocumentManagementService`, o corregir la referencia al m√©todo correcto.

### Impacto Frontend
- KB: bot√≥n "‚ò¢Ô∏è Reset" no funciona
- Admin System: "Reset Nuclear" no funciona
- KB: "Sync Directory" no funciona
- Frontend adaptado con `retries: 0`

---

## üêõ Bug 4: Retrieval No Recupera Chunks (0 de 26)

### Descripci√≥n
El endpoint `/query` retorna 200 pero con 0 chunks searched y 0 retrieved. La colecci√≥n `kb_envios23` tiene **26 chunks** (confirmado v√≠a `/stats`) pero el pipeline RAG no los consulta.

### Reproducci√≥n
```bash
curl -sS -X POST "http://167.172.225.44/api/v2/query" \
  -H "Content-Type: application/json" \
  -d '{"query":"envio de paquetes a Cuba","tenant_id":"envios23","top_k":5}' | python3 -c "
import json,sys; d=json.load(sys.stdin)
print(f'chunks_searched: {d[\"metadata\"][\"total_chunks_searched\"]}')
print(f'chunks_retrieved: {len(d.get(\"retrieved_chunks\",[]))}')
print(f'confidence: {d[\"confidence\"]}')
print(f'answer: {d[\"answer\"][:100]}...')"
```

### Resultado (2026-02-16)
```
chunks_searched: 0
chunks_retrieved: 0
confidence: 0.0
answer: Lo siento, no puedo procesar la consulta en este momento debido a un problema t√©cnico...
```

### Contexto
```bash
# La colecci√≥n S√ç tiene datos:
curl -sS "http://167.172.225.44/api/v2/stats?tenant_id=envios23"
# ‚Üí collection: kb_envios23, total_chunks: 26, categories: {faq: 26}

# Los documentos S√ç est√°n registrados:
# 7 docs total: 3 indexed (21 chunks), 4 pending
```

### Resultado Esperado
Con 26 chunks de FAQ sobre env√≠os, deber√≠a recuperar al menos 3-5 chunks relevantes con confianza > 0.

### Hip√≥tesis
1. **Similarity threshold demasiado alto** ‚Äî si qued√≥ en 0.9+ tras migraci√≥n, nada pasa el filtro
2. **Embeddings incompatibles** ‚Äî si se migraron chunks sin re-generar embeddings con el modelo actual (`sentence-transformers/paraphrase-multilingual-mpnet-base-v2`), la similitud ser√° ~0
3. **Error silenciado en retrieval** ‚Äî el pipeline podr√≠a estar catch-eando una excepci√≥n y retornando vac√≠o (el mensaje "problema t√©cnico" sugiere esto)
4. **Conexi√≥n a Qdrant/ChromaDB rota** ‚Äî el vector store podr√≠a no estar accesible para queries aunque `/stats` lea metadata

### Impacto Frontend
- Chat: respuestas gen√©ricas sin contexto
- Pipeline: 0 fuentes, 0% confianza
- DocViewer: "Sin chunks recuperados"

---

## ~~üêõ Bug 5: Documents Metadata~~ ‚úÖ RESUELTO

> Documents retorna 7 documentos correctos (3 indexed, 4 pending). Stats: 21 chunks, 1.2 MB. Vector DB: 26 chunks en `kb_envios23`.

---

## ~~üêõ Bug 6: API Keys / Conversations / Tasks~~ ‚úÖ RESUELTO (2026-02-16)

> Antes retornaban 502 (servicio no desplegado). Ahora retornan 200. Datos vac√≠os pero funcionales:
> - API Keys: `{"keys":[], "count":0}` ‚Üí 200
> - Conversations: `{"sessions":[], "total":0}` ‚Üí 200
> - Tasks: `{"tasks":[], "total":0}` ‚Üí 200

---

## üìä Resumen de Estado

| # | Grupo | Endpoints | Estado |
|---|-------|-----------|--------|
| 1 | Health/Core | `/health`, `/tenants`, `/stats`, `/models` | ‚úÖ OK |
| 2 | Agents | `/agents` CRUD | ‚úÖ OK |
| 3 | ~~API Keys~~ | `/api-keys` | ‚úÖ OK (antes 502) |
| 4 | ~~Conversations~~ | `/conversations` | ‚úÖ OK (antes 502) |
| 5 | ~~Tasks~~ | `/tasks` | ‚úÖ OK (antes 502) |
| 6 | Documents CRUD | `/documents`, `/documents/{id}`, `/documents/upload` | ‚úÖ OK (7 docs) |
| 7 | Documents Stats | `/documents/stats/summary` | ‚úÖ OK (21 chunks, 1.2 MB) |
| 8 | Documents Process | `/documents/process-pending` | ‚úÖ OK |
| 9 | Widget/Config | `/agents/{id}/widget-config` | ‚úÖ OK |
| 10 | MCP | `/mcp/health`, `/mcp/tools`, `/mcp/prompts`, `/mcp/resources` | ‚úÖ OK |
| 11 | Cache | `DELETE /cache` | ‚úÖ OK |
| 12 | Chat | `/chat/completions` | ‚úÖ OK |
| 13 | **Feedback** | `POST/GET /feedback`, `/feedback/stats` | **‚ö†Ô∏è INTERMITENTE (asyncpg)** |
| 14 | **Metrics** | `/metrics/dashboard,coverage,gaps,grounding` | **‚ùå 500 (SQLAlchemy)** |
| 15 | **Reset** | `/documents/reset-reindex` | **‚ùå 500 (missing method)** |
| 16 | **Sync** | `/documents/sync/directory` | **‚ùå 500** |
| 17 | **Retrieval** | `POST /query` | **‚ö†Ô∏è 200 pero 0/26 chunks** |

---

## üîß Resumen de Fixes Backend Requeridos

### Fix 1: asyncpg event loop (Feedback + dependientes)
**Archivos**: `pg_feedback_repository.py`, `pg_feedback_insights.py`, `pg_gap_log.py`, `pg_cost_tracker.py`  
**Error**: `RuntimeError: Task got Future attached to a different loop`  
**Soluci√≥n**: Mover `asyncpg.create_pool()` al startup handler de FastAPI en vez de crearlo en import-time.  
**Desbloquea**: Feedback POST/GET/Stats + potencialmente Metrics (dependen de feedback data)

### Fix 2: SQLAlchemy `.isnull()` (Metrics)
**Archivos**: Queries de metrics (dashboard, coverage, gaps, grounding)  
**Error**: `AttributeError: 'Column' object has no attribute 'isnull'`  
**Soluci√≥n**: Reemplazar `.isnull()` ‚Üí `.is_(None)` en todas las queries de SQLAlchemy.  
**Desbloquea**: Los 4 endpoints de `/metrics/*`

### Fix 3: Missing method (Reset/Sync)
**Archivos**: `DocumentManagementService`  
**Error**: `AttributeError: object has no attribute 'full_reset_and_reindex'`  
**Soluci√≥n**: Implementar el m√©todo o corregir la referencia.  
**Desbloquea**: `/documents/reset-reindex` + `/documents/sync/directory`

### Fix 4: Retrieval pipeline (Query)
**S√≠ntoma**: `/query` retorna 200 pero busca 0 chunks de 26 disponibles  
**Posible causa**: Error silenciado en el adapter de vector store, threshold demasiado alto, o embeddings incompatibles  
**Necesita**: Revisar logs del retrieval pipeline, verificar conexi√≥n a vector store en runtime

---

## ‚úÖ Verificaciones Post-Fix

```bash
#!/bin/bash
echo "=== Test Suite: Backend Endpoints (29 tests) ==="

# ‚îÄ‚îÄ Core ‚îÄ‚îÄ
echo -n "1. Health: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/health")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "2. Tenants LIST: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/tenants")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "3. Tenant GET: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/tenants/envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "4. Stats: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/stats?tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "5. Models: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/models")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

# ‚îÄ‚îÄ Agents / Keys / Conversations / Tasks ‚îÄ‚îÄ
echo -n "6. Agents: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/agents?tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "7. API Keys: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/api-keys?tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "8. Conversations: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/conversations?tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "9. Tasks: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/tasks?tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

# ‚îÄ‚îÄ Documents ‚îÄ‚îÄ
echo -n "10. Documents LIST: "
TOTAL=$(curl -sS "http://167.172.225.44/api/v2/documents?tenant_id=envios23" | \
  python3 -c "import json,sys;d=json.load(sys.stdin);print(d.get('total',len(d.get('documents',[]))))")
[[ "$TOTAL" -gt "0" ]] && echo "PASS ($TOTAL docs)" || echo "FAIL (0 docs)"

echo -n "11. Document GET: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/documents/0e28d5358e022c93?tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "12. Documents Stats: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/documents/stats/summary?tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "13. Process Pending: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" -X POST "http://167.172.225.44/api/v2/documents/process-pending?tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "14. Reset Reindex: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" -X POST "http://167.172.225.44/api/v2/documents/reset-reindex?tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "15. Sync Directory: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" -X POST "http://167.172.225.44/api/v2/documents/sync/directory?directory=/app/storage&tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

# ‚îÄ‚îÄ Cache / Chat ‚îÄ‚îÄ
echo -n "16. Cache DELETE: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" -X DELETE "http://167.172.225.44/api/v2/cache?tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "17. Chat Completions: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" -X POST -H "Content-Type: application/json" \
  -d '{"model":"rag","messages":[{"role":"user","content":"hola"}],"tenant_id":"envios23"}' \
  "http://167.172.225.44/api/v2/chat/completions")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

# ‚îÄ‚îÄ Query/Retrieval ‚îÄ‚îÄ
echo -n "18. Query Retrieval: "
RETRIEVED=$(curl -sS -X POST "http://167.172.225.44/api/v2/query" \
  -H "Content-Type: application/json" \
  -d '{"query":"servicios de envio a Cuba","tenant_id":"envios23","top_k":5}' | \
  python3 -c "import json,sys;d=json.load(sys.stdin);print(len(d.get('retrieved_chunks',[])))")
[[ "$RETRIEVED" -gt "0" ]] && echo "PASS ($RETRIEVED chunks)" || echo "FAIL (0 chunks of 26)"

# ‚îÄ‚îÄ Feedback ‚îÄ‚îÄ
echo -n "19. Feedback POST: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" -X POST "http://167.172.225.44/api/v2/feedback" \
  -H "Content-Type: application/json" \
  -d '{"tenant_id":"envios23","query":"test","response":"test","rating":"positive"}')
[[ "$HTTP" == "200" || "$HTTP" == "201" ]] && echo "PASS ($HTTP)" || echo "FAIL ($HTTP)"

echo -n "20. Feedback GET: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/feedback?limit=5")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "21. Feedback Stats: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/feedback/stats")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

# ‚îÄ‚îÄ Metrics ‚îÄ‚îÄ
echo -n "22. Metrics Dashboard: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/metrics/dashboard?tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "23. Metrics Coverage: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/metrics/coverage?tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "24. Metrics Gaps: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/metrics/gaps?tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "25. Metrics Grounding: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/metrics/grounding?tenant_id=envios23")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

# ‚îÄ‚îÄ MCP ‚îÄ‚îÄ
echo -n "26. MCP Health: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/mcp/health")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "27. MCP Tools: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/mcp/tools")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "28. MCP Prompts: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/mcp/prompts")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo -n "29. MCP Resources: "
HTTP=$(curl -sS -o /dev/null -w "%{http_code}" "http://167.172.225.44/api/v2/mcp/resources")
[[ "$HTTP" == "200" ]] && echo "PASS" || echo "FAIL ($HTTP)"

echo ""
echo "=== Done ==="
```
