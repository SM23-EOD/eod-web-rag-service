# [BACKEND] ðŸŸ¡ ISSUE-004: Pipeline RAG â€” ValidaciÃ³n E2E Post-Fix Embedding

**Fecha:** 2026-02-20  
**Severidad:** P1 â€” ValidaciÃ³n requerida tras resoluciÃ³n de ISSUE-002  
**Afecta:** Pipeline de 14 pasos, todos los protocolos (REST, OpenAI, MCP)  
**Prerequisito:** ISSUE-002 resuelto (embedding service healthy)  

---

## Contexto

El pipeline RAG de 14 pasos ha estado inoperativo desde al menos 2026-02-20 por dos razones secuenciales:

1. **`metadata_filters` bug** (reportado en BACKEND-ISSUE-PIPELINE-BROKEN.md) â€” Backend reportÃ³ que fue arreglado, pero no se pudo verificar porque...
2. **Embedding service caÃ­do** (ISSUE-002) â€” El pipeline falla en `retrieve_chunks` porque no puede generar embeddings de la query

El bug de `metadata_filters` fue **supuestamente arreglado** pero **no se ha podido verificar** porque el servicio de embeddings sigue caÃ­do. Una vez que ISSUE-002 se resuelva, necesitamos validaciÃ³n E2E completa del pipeline.

---

## Historial de Errores

| Fecha | Error | Paso | Estado |
|---|---|---|---|
| 2026-02-20 (AM) | `QdrantDBService.query() got unexpected kwarg 'metadata_filters'` | `retrieve_chunks` | Â¿Arreglado? |
| 2026-02-20 (PM) | `[Errno 111] Connection refused` | `retrieve_chunks` | Transitorio (Qdrant restart) |
| 2026-02-20 (PM) | `[Errno -3] Temporary failure in name resolution` | `retrieve_chunks` | **ACTIVO** â€” embedding DNS |

---

## Objective Eval Spec (Mandatorio)

### EVAL-004: ValidaciÃ³n End-to-End del Pipeline RAG

**Objetivo:** Confirmar que el pipeline de 14 pasos funciona correctamente a travÃ©s de los 3 protocolos (REST, OpenAI, MCP) tras las correcciones de ISSUE-002 y el fix de `metadata_filters`.

#### Setup

- Tenant: `eod-sm23`
- Agent: `envio23`  
- ColecciÃ³n: `kb_eod-sm23` (1223 chunks)
- Queries de test: 5 queries representativas del dominio

#### Queries de Test

| # | Query | Dominio | Chunks esperados |
|---|---|---|---|
| Q1 | "regulaciones de envÃ­o a Cuba" | regulaciones | > 0 chunks, confianza > 0 |
| Q2 | "Â¿puedo enviar baterÃ­as de litio?" | restricciones | > 0 chunks |
| Q3 | "documentos necesarios para importar medicamentos" | documentaciÃ³n | > 0 chunks |
| Q4 | "tarifas de envÃ­o internacional" | precios | > 0 chunks |
| Q5 | "horarios de atenciÃ³n al cliente" | servicio | > 0 chunks (o respuesta "no tengo info" con confianza 0 si no hay datos) |

#### Protocolo 1: REST `/query`

```bash
for Q in "regulaciones de envÃ­o a Cuba" "puedo enviar baterÃ­as de litio" "documentos para importar medicamentos" "tarifas de envÃ­o internacional" "horarios de atenciÃ³n al cliente"; do
  echo "=== Query: $Q ==="
  curl -s -X POST "http://167.172.225.44:9999/api/v2/query" \
    -H "Content-Type: application/json" \
    -d "{\"query\":\"$Q\",\"tenant_id\":\"eod-sm23\",\"agent_id\":\"envio23\",\"top_k\":5}" | python3 -c "
import json,sys; d=json.load(sys.stdin)
m = d.get('metadata',{})
print(f'  confidence: {d.get(\"confidence\")}')
print(f'  chunks_searched: {m.get(\"total_chunks_searched\")}')
print(f'  chunks_retrieved: {m.get(\"chunks_retrieved\",len(d.get(\"retrieved_chunks\",[])))}')
print(f'  error_step: {m.get(\"error_step\",\"none\")}')
print(f'  cached: {d.get(\"cached\",False)}')
print(f'  answer: {d.get(\"answer\",\"\")[:80]}...')
print()
"
done
```

#### Protocolo 2: OpenAI `/chat/completions`

```bash
curl -s -X POST "http://167.172.225.44:9999/api/v2/chat/completions" \
  -H "Content-Type: application/json" \
  -d '{
    "model":"envio23",
    "messages":[{"role":"user","content":"regulaciones de envÃ­o a Cuba"}],
    "tenant_id":"eod-sm23",
    "agent_id":"envio23"
  }' | python3 -c "
import json,sys; d=json.load(sys.stdin)
if 'error' in d:
    print(f'FAIL: {d[\"error\"]}: {d.get(\"message\",\"\")}')
else:
    c = d.get('choices',[{}])[0]
    msg = c.get('message',{}).get('content','')
    print(f'PASS: {msg[:120]}...')
"
```

#### Protocolo 3: MCP `generate_rag_answer`

```bash
curl -s -X POST "http://167.172.225.44:9999/api/v2/mcp/tools/call" \
  -H "Content-Type: application/json" \
  -d '{
    "tool_name":"generate_rag_answer",
    "arguments":{"query":"regulaciones de envÃ­o a Cuba","tenant_id":"eod-sm23","agent_id":"envio23"}
  }' | python3 -c "
import json,sys; d=json.load(sys.stdin)
if not d.get('success'):
    print(f'FAIL: {d.get(\"error\",\"unknown\")}')
else:
    r = d.get('result','')
    has_content = 'Confianza: 0.00%' not in r
    print(f'PASS: has_content={has_content}')
    print(r[:200])
"
```

#### MÃ©tricas de AceptaciÃ³n

| MÃ©trica | Criterio |
|---|---|
| REST `/query` â†’ error_step | `none` (sin error) para todas las queries |
| REST `/query` â†’ chunks_searched | `> 0` para al menos 4/5 queries |
| REST `/query` â†’ confidence | `> 0.0` para queries con chunks relevantes |
| REST `/query` â†’ answer | Respuesta coherente con el dominio, no genÃ©rica |
| OpenAI `/chat/completions` | 200 OK, respuesta con contenido RAG |
| MCP `generate_rag_answer` | success=true, respuesta con confianza > 0 |
| MCP `search_knowledge_base` | Retorna chunks reales con scores > 0.5 |
| Latencia E2E REST | < 5 segundos (pipeline completo) |

#### Regresiones a verificar

| RegresiÃ³n | Test |
|---|---|
| `metadata_filters` no reaparece | Query con `document_ids` filter si soportado |
| Cross-tenant isolation | Query con `tenant_id=sm23-dani` NO retorna datos de `eod-sm23` |
| Cache funciona | Segunda query idÃ©ntica â†’ `cached: true` |

---

## Acciones Post-ValidaciÃ³n

### Si PASA todo:
1. Cerrar ISSUE-002, ISSUE-004
2. Desplegar frontend actualizado (`deploy.sh`)
3. Verificar que dashboards (draga.html, admin.html, tenant.html) cargan datos

### Si FALLA pipeline pero embedding funciona:
1. El bug de `metadata_filters` NO fue arreglado â†’ reabrir con evidencia fresca
2. Capturar `error_step` y `error_detail` exactos
3. Revisar docker logs del backend: `docker logs hex-rag-service --tail 100`

### Si FALLA OpenAI protocol:
1. Verificar `llm.ok` en health/deep (actualmente `true`, latencia 112ms)
2. Capturar error exacto del endpoint `/chat/completions`

---

## Referencias

- [BACKEND-ISSUE-PIPELINE-BROKEN.md](BACKEND-ISSUE-PIPELINE-BROKEN.md) â€” Issue original (metadata_filters)
- [ISSUE-002: Embedding Service Down](BACKEND-ISSUE-002-EMBEDDING-SERVICE-DOWN.md) â€” Prerrequisito
- [EVAL-001: OpenAI Embeddings](adr/EVAL-001-openai-embeddings-online.md) â€” Datos de referencia
